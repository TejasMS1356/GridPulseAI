{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfXelNDjDVOb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e543bbee"
      },
      "source": [
        "# Task\n",
        "Generate a synthetic dataset with at least 5000 samples for predicting 'Next_Hour_Load_MW' based on 'Time', 'Current_Load_MW', 'Temperature_C', 'Area_Type', and 'Consumers', ensuring specified logical relationships. Then, prepare the data, train and evaluate Linear Regression, Random Forest Regressor, and XGBoost Regressor models, select the best one, and implement a prediction function that calculates 'Utilization' and 'Risk' based on new inputs. Finally, visualize model performance, predictions vs. actuals, and feature importance, and provide a summary of the model development with an example prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "854d32ff"
      },
      "source": [
        "## Generate Synthetic Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic dataset with at least 5000 samples, including columns 'Time', 'Current_Load_MW', 'Temperature_C', 'Area_Type', 'Consumers', and 'Next_Hour_Load_MW'. Ensure the data reflects the specified logical relationships: Commercial and Industrial areas have higher load, higher temperature slightly increases load, and evening hours have peak demand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e7e37b"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to import the necessary libraries as instructed, which include `pandas` for data manipulation, `numpy` for numerical operations, `random` for specific random choices, and `datetime` for time-related features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8b9d8b",
        "outputId": "00de630e-ead0-4d8a-fbe2-fd64f3d11acf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83af2e7c"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to generate the synthetic dataset with at least 5000 samples, incorporating all specified columns and logical relationships. This involves defining sample size, generating values for 'Time', 'Current_Load_MW', 'Temperature_C', 'Area_Type', and 'Consumers', and then calculating 'Next_Hour_Load_MW' based on the given rules. Finally, all this data will be assembled into a pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afc8552f",
        "outputId": "388a9f23-b925-47d0-bc4a-98f7494ea45c"
      },
      "source": [
        "n_samples = 5000\n",
        "\n",
        "# 3. Create lists for categorical features\n",
        "area_types = ['Residential', 'Commercial', 'Industrial']\n",
        "\n",
        "# Initialize lists to store generated data\n",
        "data = {\n",
        "    'Time': [],\n",
        "    'Current_Load_MW': [],\n",
        "    'Temperature_C': [],\n",
        "    'Area_Type': [],\n",
        "    'Consumers': [],\n",
        "    'Next_Hour_Load_MW': []\n",
        "}\n",
        "\n",
        "# Generate synthetic data\n",
        "for _ in range(n_samples):\n",
        "    # a. 'Time': Generate hourly timestamps (0-23)\n",
        "    hour = random.randint(0, 23)\n",
        "    data['Time'].append(hour)\n",
        "\n",
        "    # b. 'Current_Load_MW': Base load with variation\n",
        "    current_load = random.uniform(500, 2000) # Base load range\n",
        "    data['Current_Load_MW'].append(current_load)\n",
        "\n",
        "    # c. 'Temperature_C': Realistic temperature values\n",
        "    temperature = random.uniform(5, 35) # Realistic temperature range\n",
        "    data['Temperature_C'].append(temperature)\n",
        "\n",
        "    # d. 'Area_Type': Randomly select area type\n",
        "    area_type = random.choice(area_types)\n",
        "    data['Area_Type'].append(area_type)\n",
        "\n",
        "    # e. 'Consumers': Generate consumers based on area type\n",
        "    if area_type == 'Residential':\n",
        "        consumers = random.randint(1000, 5000)\n",
        "    elif area_type == 'Commercial':\n",
        "        consumers = random.randint(3000, 10000)\n",
        "    else: # Industrial\n",
        "        consumers = random.randint(5000, 15000)\n",
        "    data['Consumers'].append(consumers)\n",
        "\n",
        "    # 5. Calculate 'Next_Hour_Load_MW' with logical relationships\n",
        "    next_hour_load = current_load * random.uniform(0.9, 1.1) # Baseline influenced by current load\n",
        "\n",
        "    # b. Area_Type influence (Commercial and Industrial have higher load)\n",
        "    if area_type == 'Commercial':\n",
        "        next_hour_load += random.uniform(100, 300)\n",
        "    elif area_type == 'Industrial':\n",
        "        next_hour_load += random.uniform(200, 500)\n",
        "\n",
        "    # c. Temperature_C influence (higher temperature slightly increases load)\n",
        "    next_hour_load += temperature * random.uniform(2, 5) # Positive coefficient\n",
        "\n",
        "    # d. Time influence (evening hours have peak demand)\n",
        "    if 18 <= hour <= 22: # Peak demand hours\n",
        "        next_hour_load += random.uniform(150, 400)\n",
        "    elif 6 <= hour <= 9: # Morning peak\n",
        "        next_hour_load += random.uniform(50, 200)\n",
        "    elif 0 <= hour <= 5: # Low demand hours\n",
        "        next_hour_load *= random.uniform(0.8, 1.0)\n",
        "\n",
        "    # e. Consumers influence\n",
        "    next_hour_load += consumers * random.uniform(0.05, 0.15)\n",
        "\n",
        "    # f. Add random noise\n",
        "    next_hour_load += random.uniform(-50, 50)\n",
        "\n",
        "    # Ensure load is not negative\n",
        "    next_hour_load = max(50, next_hour_load)\n",
        "\n",
        "    data['Next_Hour_Load_MW'].append(next_hour_load)\n",
        "\n",
        "# 6. Assemble into a Pandas DataFrame\n",
        "df_synthetic = pd.DataFrame(data)\n",
        "\n",
        "print(f\"Synthetic dataset created with {len(df_synthetic)} samples.\")\n",
        "print(df_synthetic.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset created with 5000 samples.\n",
            "   Time  Current_Load_MW  Temperature_C    Area_Type  Consumers  \\\n",
            "0    20      1070.289162      16.268644  Residential       4827   \n",
            "1    11       783.853269      11.229392   Commercial       6089   \n",
            "2    21      1351.323380      10.886659  Residential       3333   \n",
            "3    20      1524.933377       6.147333   Industrial       6702   \n",
            "4    16      1185.600150      33.883281   Industrial       8719   \n",
            "\n",
            "   Next_Hour_Load_MW  \n",
            "0        2145.826962  \n",
            "1        1856.835088  \n",
            "2        1918.915530  \n",
            "3        3138.209283  \n",
            "4        2641.733058  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac56170f"
      },
      "source": [
        "**Reasoning**:\n",
        "The synthetic dataset has been generated. To ensure its quality and characteristics align with the requirements, it's crucial to inspect its structure and descriptive statistics. This will help verify data types, check for any anomalies, and confirm that the generated values broadly follow the intended distributions and relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "78e40734",
        "outputId": "8c6e9b11-3cbb-4a5e-9a79-327276197008"
      },
      "source": [
        "print('DataFrame Info:')\n",
        "df_synthetic.info()\n",
        "print('\\nDataFrame Descriptive Statistics:')\n",
        "df_synthetic.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Time               5000 non-null   int64  \n",
            " 1   Current_Load_MW    5000 non-null   float64\n",
            " 2   Temperature_C      5000 non-null   float64\n",
            " 3   Area_Type          5000 non-null   object \n",
            " 4   Consumers          5000 non-null   int64  \n",
            " 5   Next_Hour_Load_MW  5000 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(1)\n",
            "memory usage: 234.5+ KB\n",
            "\n",
            "DataFrame Descriptive Statistics:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Time  Current_Load_MW  Temperature_C    Area_Type  \\\n",
              "count   5000.000000      5000.000000    5000.000000         5000   \n",
              "unique          NaN              NaN            NaN            3   \n",
              "top             NaN              NaN            NaN  Residential   \n",
              "freq            NaN              NaN            NaN         1694   \n",
              "mean      11.363000      1253.969911      20.056235          NaN   \n",
              "std        6.974823       435.889717       8.625976          NaN   \n",
              "min        0.000000       500.089487       5.006003          NaN   \n",
              "25%        5.000000       872.662518      12.537859          NaN   \n",
              "50%       11.000000      1253.202975      19.954888          NaN   \n",
              "75%       17.000000      1639.676026      27.563705          NaN   \n",
              "max       23.000000      1998.922677      34.997241          NaN   \n",
              "\n",
              "           Consumers  Next_Hour_Load_MW  \n",
              "count    5000.000000        5000.000000  \n",
              "unique           NaN                NaN  \n",
              "top              NaN                NaN  \n",
              "freq             NaN                NaN  \n",
              "mean     6482.361200        2196.333988  \n",
              "std      3558.597155         690.736398  \n",
              "min      1003.000000         607.507543  \n",
              "25%      3618.500000        1701.221101  \n",
              "50%      5886.000000        2159.220173  \n",
              "75%      8966.000000        2650.984339  \n",
              "max     15000.000000        4743.284618  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88f4b157-2f1f-4a68-ba70-7d84362b3a57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Current_Load_MW</th>\n",
              "      <th>Temperature_C</th>\n",
              "      <th>Area_Type</th>\n",
              "      <th>Consumers</th>\n",
              "      <th>Next_Hour_Load_MW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Residential</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1694</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11.363000</td>\n",
              "      <td>1253.969911</td>\n",
              "      <td>20.056235</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6482.361200</td>\n",
              "      <td>2196.333988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.974823</td>\n",
              "      <td>435.889717</td>\n",
              "      <td>8.625976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3558.597155</td>\n",
              "      <td>690.736398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>500.089487</td>\n",
              "      <td>5.006003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1003.000000</td>\n",
              "      <td>607.507543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>872.662518</td>\n",
              "      <td>12.537859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3618.500000</td>\n",
              "      <td>1701.221101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>1253.202975</td>\n",
              "      <td>19.954888</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5886.000000</td>\n",
              "      <td>2159.220173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1639.676026</td>\n",
              "      <td>27.563705</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8966.000000</td>\n",
              "      <td>2650.984339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>1998.922677</td>\n",
              "      <td>34.997241</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>4743.284618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88f4b157-2f1f-4a68-ba70-7d84362b3a57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88f4b157-2f1f-4a68-ba70-7d84362b3a57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88f4b157-2f1f-4a68-ba70-7d84362b3a57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_synthetic\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1764.026592071857,\n        \"min\": 0.0,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          11.363,\n          11.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Current_Load_MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1466.3713110740778,\n        \"min\": 435.889717289542,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1253.9699114001921,\n          1253.2029751712826,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1761.2918346227425,\n        \"min\": 5.00600334910394,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20.056235404152627,\n          19.954887850125008,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Area_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"1694\",\n          \"5000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Consumers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4265.444632876032,\n        \"min\": 1003.0,\n        \"max\": 15000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6482.3612,\n          5886.0,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Next_Hour_Load_MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1647.4490777156648,\n        \"min\": 607.5075426713826,\n        \"max\": 5000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2196.3339875155084,\n          2159.220172839693,\n          5000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0a3b7d6"
      },
      "source": [
        "## Prepare Data for Modeling\n",
        "\n",
        "### Subtask:\n",
        "Split the generated dataset into training and testing sets (80% train, 20% test) and encode categorical features like 'Area_Type', preparing the data for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73eb51a1"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires splitting the data into training and testing sets and encoding categorical features. This step involves importing necessary libraries, defining features and target, performing the split, applying one-hot encoding to 'Area_Type' for both training and testing sets, and then reassembling the processed data into new DataFrames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "889cfbab",
        "outputId": "96f31b5b-a4e5-4e8a-f90f-5241b62c8c2f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "print(\"sklearn.model_selection.train_test_split and sklearn.preprocessing.OneHotEncoder imported successfully.\")\n",
        "\n",
        "# 2. Define features (X) and target (y)\n",
        "X = df_synthetic.drop('Next_Hour_Load_MW', axis=1)\n",
        "y = df_synthetic['Next_Hour_Load_MW']\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data split into training and testing sets: X_train shape {X_train.shape}, X_test shape {X_test.shape}\")\n",
        "\n",
        "# 4. Identify the categorical features\n",
        "categorical_features = ['Area_Type']\n",
        "\n",
        "# 5. Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "# 6. Fit the encoder to the categorical features in X_train and transform both X_train and X_test\n",
        "X_train_categorical_encoded = encoder.fit_transform(X_train[categorical_features])\n",
        "X_test_categorical_encoded = encoder.transform(X_test[categorical_features])\n",
        "\n",
        "# 7. Create DataFrames for the one-hot encoded features\n",
        "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
        "X_train_encoded_df = pd.DataFrame(X_train_categorical_encoded, columns=encoded_feature_names, index=X_train.index)\n",
        "X_test_encoded_df = pd.DataFrame(X_test_categorical_encoded, columns=encoded_feature_names, index=X_test.index)\n",
        "\n",
        "# 8. Drop the original 'Area_Type' column from X_train and X_test\n",
        "X_train_numerical = X_train.drop(categorical_features, axis=1)\n",
        "X_test_numerical = X_test.drop(categorical_features, axis=1)\n",
        "\n",
        "# 9. Concatenate the numerical features with their respective one-hot encoded DataFrames\n",
        "X_train_processed = pd.concat([X_train_numerical, X_train_encoded_df], axis=1)\n",
        "X_test_processed = pd.concat([X_test_numerical, X_test_encoded_df], axis=1)\n",
        "\n",
        "print(f\"X_train_processed shape: {X_train_processed.shape}\")\n",
        "print(f\"X_test_processed shape: {X_test_processed.shape}\")\n",
        "print(\"First 5 rows of X_train_processed:\")\n",
        "print(X_train_processed.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn.model_selection.train_test_split and sklearn.preprocessing.OneHotEncoder imported successfully.\n",
            "Data split into training and testing sets: X_train shape (4000, 5), X_test shape (1000, 5)\n",
            "X_train_processed shape: (4000, 7)\n",
            "X_test_processed shape: (1000, 7)\n",
            "First 5 rows of X_train_processed:\n",
            "      Time  Current_Load_MW  Temperature_C  Consumers  Area_Type_Commercial  \\\n",
            "4227     7      1319.530865       7.833202       9739                   1.0   \n",
            "4676    14       732.264196      27.934641       4327                   1.0   \n",
            "800      4      1341.173973      11.249824       4616                   0.0   \n",
            "3671    20       668.614528      10.843448       7863                   0.0   \n",
            "4193     2      1688.920746      16.506578       4611                   1.0   \n",
            "\n",
            "      Area_Type_Industrial  Area_Type_Residential  \n",
            "4227                   0.0                    0.0  \n",
            "4676                   0.0                    0.0  \n",
            "800                    0.0                    1.0  \n",
            "3671                   1.0                    0.0  \n",
            "4193                   0.0                    0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87171924"
      },
      "source": [
        "## Train and Evaluate Models\n",
        "\n",
        "### Subtask:\n",
        "Train Linear Regression, Random Forest Regressor, and XGBoost Regressor models on the training data. Evaluate each model's performance on the test set using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R² score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84b52f41"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to import all the necessary classes and functions for model training and evaluation, including `LinearRegression`, `RandomForestRegressor`, `XGBRegressor`, and evaluation metrics like `mean_absolute_error`, `mean_squared_error`, and `r2_score`. This sets up the environment for the subsequent model training and assessment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5765ab",
        "outputId": "e8407295-2654-4c4c-9323-f628ed0b2c2f"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "print(\"LinearRegression, RandomForestRegressor, XGBRegressor, and evaluation metrics imported successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression, RandomForestRegressor, XGBRegressor, and evaluation metrics imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a855914"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary libraries are imported, the next step is to instantiate, train, and evaluate each of the three models (Linear Regression, Random Forest Regressor, and XGBoost Regressor) as per the instructions. This involves fitting the models to the training data, making predictions on the test data, and then calculating and storing their respective MAE, RMSE, and R² scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e03809e1",
        "outputId": "cc2fe6f9-39b1-4a2e-8d6e-88c2c4e8a14f"
      },
      "source": [
        "model_performance = {}\n",
        "\n",
        "# 3. Instantiate and train a Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# 4. Make predictions on X_test_processed using the trained Linear Regression model\n",
        "y_pred_lr = lr_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Calculate MAE, RMSE, and R² scores for the Linear Regression model\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "print(\"\\n--- Linear Regression Performance ---\")\n",
        "print(f\"MAE: {mae_lr:.2f}\")\n",
        "print(f\"RMSE: {rmse_lr:.2f}\")\n",
        "print(f\"R-squared: {r2_lr:.2f}\")\n",
        "\n",
        "model_performance['Linear Regression'] = {'MAE': mae_lr, 'RMSE': rmse_lr, 'R2': r2_lr}\n",
        "\n",
        "# 6. Instantiate and train a RandomForestRegressor model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# 7. Make predictions on X_test_processed using the trained Random Forest model\n",
        "y_pred_rf = rf_model.predict(X_test_processed)\n",
        "\n",
        "# 8. Calculate MAE, RMSE, and R² scores for the Random Forest model\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n--- Random Forest Regressor Performance ---\")\n",
        "print(f\"MAE: {mae_rf:.2f}\")\n",
        "print(f\"RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"R-squared: {r2_rf:.2f}\")\n",
        "\n",
        "model_performance['Random Forest'] = {'MAE': mae_rf, 'RMSE': rmse_rf, 'R2': r2_rf}\n",
        "\n",
        "# 9. Instantiate and train an XGBRegressor model\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "xgb_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# 10. Make predictions on X_test_processed using the trained XGBoost model\n",
        "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
        "\n",
        "# 11. Calculate MAE, RMSE, and R² scores for the XGBoost model\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"\\n--- XGBoost Regressor Performance ---\")\n",
        "print(f\"MAE: {mae_xgb:.2f}\")\n",
        "print(f\"RMSE: {rmse_xgb:.2f}\")\n",
        "print(f\"R-squared: {r2_xgb:.2f}\")\n",
        "\n",
        "model_performance['XGBoost'] = {'MAE': mae_xgb, 'RMSE': rmse_xgb, 'R2': r2_xgb}\n",
        "\n",
        "# 12. Display stored model performance for comparison\n",
        "print(\"\\n--- All Model Performance Summary ---\")\n",
        "for model_name, metrics in model_performance.items():\n",
        "    print(f\"{model_name}: MAE={metrics['MAE']:.2f}, RMSE={metrics['RMSE']:.2f}, R2={metrics['R2']:.2f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Regression Performance ---\n",
            "MAE: 201.64\n",
            "RMSE: 255.00\n",
            "R-squared: 0.86\n",
            "\n",
            "--- Random Forest Regressor Performance ---\n",
            "MAE: 203.77\n",
            "RMSE: 266.04\n",
            "R-squared: 0.85\n",
            "\n",
            "--- XGBoost Regressor Performance ---\n",
            "MAE: 199.23\n",
            "RMSE: 264.88\n",
            "R-squared: 0.85\n",
            "\n",
            "--- All Model Performance Summary ---\n",
            "Linear Regression: MAE=201.64, RMSE=255.00, R2=0.86\n",
            "Random Forest: MAE=203.77, RMSE=266.04, R2=0.85\n",
            "XGBoost: MAE=199.23, RMSE=264.88, R2=0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73b72ece"
      },
      "source": [
        "## Select Best Model\n",
        "\n",
        "### Subtask:\n",
        "Identify and select the best-performing model among Linear Regression, Random Forest, and XGBoost based on the evaluation metrics (e.g., lowest RMSE or MAE). This model will be used for predictions and feature importance analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4c7ab23"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to programmatically identify the best performing model based on the RMSE metric from the 'model_performance' dictionary, as specified in the instructions. This involves iterating through the dictionary, comparing RMSE values, and storing the name and the model object of the best performing model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49e335e7",
        "outputId": "4463377e-6f45-42e5-fab0-e9304a5b5ca4"
      },
      "source": [
        "best_model_name = None\n",
        "lowest_rmse = float('inf')\n",
        "best_model = None\n",
        "\n",
        "# Create a dictionary mapping model names to their objects\n",
        "models = {\n",
        "    'Linear Regression': lr_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'XGBoost': xgb_model\n",
        "}\n",
        "\n",
        "# Iterate through the model_performance dictionary to find the best model\n",
        "for model_name, metrics in model_performance.items():\n",
        "    if metrics['RMSE'] < lowest_rmse:\n",
        "        lowest_rmse = metrics['RMSE']\n",
        "        best_model_name = model_name\n",
        "\n",
        "# Retrieve the best model object\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\n--- Best Performing Model: {best_model_name} ---\")\n",
        "print(f\"MAE: {model_performance[best_model_name]['MAE']:.2f}\")\n",
        "print(f\"RMSE: {model_performance[best_model_name]['RMSE']:.2f}\")\n",
        "print(f\"R-squared: {model_performance[best_model_name]['R2']:.2f}\")\n",
        "print(f\"Best model object type: {type(best_model)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Best Performing Model: Linear Regression ---\n",
            "MAE: 201.64\n",
            "RMSE: 255.00\n",
            "R-squared: 0.86\n",
            "Best model object type: <class 'sklearn.linear_model._base.LinearRegression'>\n"
          ]
        }
      ]
    }
  ]
}